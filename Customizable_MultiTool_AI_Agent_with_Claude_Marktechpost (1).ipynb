{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Customizable Multi-Tool AI Agents with LangGraph, Claude, and Personas\n",
        "\n",
        "This notebook demonstrates how to build AI agents that can use multiple tools (functions) to answer questions and complete tasks. It utilizes LangGraph for creating stateful, graph-based agents and integrates with Anthropic's Claude model via LangChain. \n",
        "\n",
        "A key feature of this notebook is the implementation of a **multi-persona agent system**. It showcases how to define and instantiate multiple AI assistants, each embodying a distinct 'dissertation committee persona' with its own characteristics, expertise, and communication style. These personas are inspired by archetypes described in the `dissertation_committee_personas.ipynb` notebook.\n",
        "\n",
        "You will be able to select and interact with these different persona agents, each leveraging the same set of underlying tools but guided by its unique persona."
      ],
      "metadata": {
        "id": "notebook_title_intro_markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Package Installation\n",
        "\n",
        "First, we install the necessary Python packages for LangGraph, LangChain, Anthropic, and other utilities."
      ],
      "metadata": {
        "id": "package_installation_markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_packages():\n",
        "    packages = [\n",
        "        \"langgraph\",\n",
        "        \"langchain\",\n",
        "        \"langchain-anthropic\",\n",
        "        \"langchain-community\",\n",
        "        \"requests\",\n",
        "        \"python-dotenv\",\n",
        "        \"duckduckgo-search\"\n",
        "    ]\n",
        "\n",
        "    for package in packages:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
        "            print(f\"‚úì Installed {package}\")\n",
        "        except subprocess.CalledProcessError:\n",
        "            print(f\"‚úó Failed to install {package}\")\n",
        "\n",
        "print(\"Installing required packages...\")\n",
        "install_packages()\n",
        "print(\"Installation complete!\\n\")"
      ],
      "metadata": {
        "id": "ojhopXxMzkIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. API Key Setup\n",
        "\n",
        "Set your Anthropic API key here. If you don't have one, the notebook will use a mock LLM for demonstration purposes."
      ],
      "metadata": {
        "id": "api_key_markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_persona_agents():\n",
        "    \"\"\"Allows users to select and interact with different persona agents.\"\"\"\n",
        "    if 'persona_agents' not in globals() or not persona_agents: # Check if persona_agents dictionary is populated\n",
        "        print(\"ERROR: No persona agents found or persona_agents not in global scope. Please ensure they are created before calling this function.\")\n",
        "        return\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nü§ñ Welcome to the Persona Agent Chat System!\")\n",
        "        print(\"Available Personas:\")\n",
        "        persona_names = list(persona_agents.keys())\n",
        "        for i, name in enumerate(persona_names):\n",
        "            print(f\"  {i+1}. {name}\")\n",
        "        print(\"  0. Quit\")\n",
        "\n",
        "        try:\n",
        "            choice = input(\"Select a persona by number or name (or type '0' or 'quit' to exit): \").strip()\n",
        "            if choice.lower() in ['0', 'quit']:\n",
        "                print(\"Exiting Persona Agent Chat System. Goodbye!\")\n",
        "                break\n",
        "\n",
        "            selected_agent = None\n",
        "            selected_persona_name = None\n",
        "\n",
        "            if choice.isdigit():\n",
        "                idx = int(choice) - 1\n",
        "                if 0 <= idx < len(persona_names):\n",
        "                    selected_persona_name = persona_names[idx]\n",
        "                    selected_agent = persona_agents[selected_persona_name]\n",
        "            else:\n",
        "                # Allow selection by name (case-insensitive, partial match on the key)\n",
        "                for name_key in persona_names:\n",
        "                    if choice.lower() in name_key.lower():\n",
        "                        selected_persona_name = name_key\n",
        "                        selected_agent = persona_agents[name_key]\n",
        "                        print(f\"(Interpreted selection as: {selected_persona_name})\")\n",
        "                        break\n",
        "            \n",
        "            if not selected_agent:\n",
        "                print(\"Invalid selection. Please try again.\")\n",
        "                continue\n",
        "\n",
        "            thread_id = f\"persona-chat-{selected_persona_name.replace(' ', '_').replace('/', '_')}\" # Ensure thread_id is fs-safe\n",
        "            config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "\n",
        "            print(f\"\\n--- You are now chatting with {selected_persona_name} ---\")\n",
        "            print(\"Type 'switch' to choose another persona, or 'quit' to exit the chat system.\")\n",
        "            print(\"Type 'help' for available commands with this persona.\")\n",
        "\n",
        "            while True:\n",
        "                user_input = input(f\"You ({selected_persona_name}): \").strip()\n",
        "\n",
        "                if user_input.lower() == 'switch':\n",
        "                    print(f\"Switching from {selected_persona_name}...\")\n",
        "                    break \n",
        "                elif user_input.lower() == 'quit':\n",
        "                    print(\"Exiting Persona Agent Chat System. Goodbye!\")\n",
        "                    return \n",
        "                elif user_input.lower() == 'help':\n",
        "                    print(\"\\nAvailable commands:\")\n",
        "                    print(f\"‚Ä¢ Any message to chat with {selected_persona_name}\")\n",
        "                    print(\"‚Ä¢ 'switch': Go back to persona selection menu.\")\n",
        "                    print(\"‚Ä¢ 'quit': Exit the chat system entirely.\")\n",
        "                    # Example of how to list tools if they are attached to the compiled app, common in some LangGraph setups\n",
        "                    # For this specific setup, tools are part of the definition of the agent, not easily listed from compiled app without specific structure.\n",
        "                    # We can refer to the global `tools` list for a general idea.\n",
        "                    global_tool_names = [tool.name for tool in tools] # Access the global `tools` list\n",
        "                    print(f\"‚Ä¢ This persona can use tools like: {', '.join(global_tool_names)}.\")\n",
        "                    print(\"\")\n",
        "                    continue\n",
        "                elif not user_input:\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    response = selected_agent.invoke(\n",
        "                        {\"messages\": [HumanMessage(content=user_input)]},\n",
        "                        config=config\n",
        "                    )\n",
        "                    last_message = response[\"messages\"][-1]\n",
        "                    print(f\"{selected_persona_name} Agent: {last_message.content}\\n\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error during agent interaction: {str(e)}\\n\")\n",
        "                    print(\"This might be due to API key issues or network problems.\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nExiting Persona Agent Chat System. Goodbye!\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred in the persona selection loop: {str(e)}\\n\")\n",
        "            # break # Optionally break on major errors\n",
        "\n"
      ],
      "metadata": {
        "id": "chat_with_persona_function_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import math\n",
        "import requests\n",
        "from typing import Dict, List, Any, Annotated, TypedDict\n",
        "from datetime import datetime\n",
        "import operator\n",
        "\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
        "from langchain_core.tools import tool\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from duckduckgo_search import DDGS"
      ],
      "metadata": {
        "id": "kVNNa7GzzmW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"ANTHROPIC_API_KEY\"] = \"Use Your API Key Here\"\n",
        "\n",
        "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")"
      ],
      "metadata": {
        "id": "bcmEtjBCzn42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "\n",
        "# Agent State and Tool Definitions are placed before agent creation logic"
      ],
      "metadata": {
        "id": "agent_state_markdown_anchor"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Agent State Definition\n",
        "\n",
        "This defines the structure of the state that will be passed around the graph. It includes a list of messages that accumulate over the conversation."
      ],
      "metadata": {
        "id": "agent_state_definition_markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]"
      ],
      "metadata": {
        "id": "UILkpo2KzvlW" # Original ID of AgentState cell, now split for markdown
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Tool Definitions\n",
        "\n",
        "These are the tools our agents can use. Each tool is decorated with `@tool` and has a clear docstring explaining its purpose, arguments, and return value. The tools include:\n",
        "- `calculator`: Performs mathematical calculations.\n",
        "- `web_search`: Searches the web using DuckDuckGo.\n",
        "- `weather_info`: Provides mock weather information for demo purposes.\n",
        "- `text_analyzer`: Analyzes text statistics.\n",
        "- `current_time`: Gets the current date and time."
      ],
      "metadata": {
        "id": "tool_definitions_markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def calculator(expression: str) -> str:\n",
        "    \"\"\"\n",
        "    Perform mathematical calculations. Supports basic arithmetic, trigonometry, and more.\n",
        "\n",
        "    Args:\n",
        "        expression: Mathematical expression as a string (e.g., \"2 + 3 * 4\", \"sin(3.14159/2)\")\n",
        "\n",
        "    Returns:\n",
        "        Result of the calculation as a string\n",
        "    \"\"\"\n",
        "    try:\n",
        "        allowed_names = {\n",
        "            'abs': abs, 'round': round, 'min': min, 'max': max,\n",
        "            'sum': sum, 'pow': pow, 'sqrt': math.sqrt,\n",
        "            'sin': math.sin, 'cos': math.cos, 'tan': math.tan,\n",
        "            'log': math.log, 'log10': math.log10, 'exp': math.exp,\n",
        "            'pi': math.pi, 'e': math.e\n",
        "        }\n",
        "\n",
        "        expression = expression.replace('^', '**')\n",
        "\n",
        "        result = eval(expression, {\"__builtins__\": {}}, allowed_names)\n",
        "        return f\"Result: {result}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error in calculation: {str(e)}\""
      ],
      "metadata": {
        "id": "calculator_tool_cell" # Made up ID for clarity, was part of UILkpo2KzvlW
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. LLM and Agent Creation Functions\n",
        "\n",
        "The following cells define functions to:\n",
        "1.  `create_persona_llm`: Initialize the ChatAnthropic model with a specific system prompt for a given persona.\n",
        "2.  `create_persona_agent`: Construct a LangGraph agent for a given persona, equipped with the persona-specific LLM and a list of tools.\n",
        "3.  `create_llm`: The original function to create a generic LLM (can be used for a default agent if needed)."
      ],
      "metadata": {
        "id": "llm_agent_creation_markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def web_search(query: str, num_results: int = 3) -> str:\n",
        "    \"\"\"\n",
        "    Search the web for information using DuckDuckGo.\n",
        "\n",
        "    Args:\n",
        "        query: Search query string\n",
        "        num_results: Number of results to return (default: 3, max: 10)\n",
        "\n",
        "    Returns:\n",
        "        Search results as formatted string\n",
        "    \"\"\"\n",
        "    try:\n",
        "        num_results = min(max(num_results, 1), 10)\n",
        "\n",
        "        with DDGS() as ddgs:\n",
        "            results = list(ddgs.text(query, max_results=num_results))\n",
        "\n",
        "        if not results:\n",
        "            return f\"No search results found for: {query}\"\n",
        "\n",
        "        formatted_results = f\"Search results for '{query}':\\n\\n\"\n",
        "        for i, result in enumerate(results, 1):\n",
        "            formatted_results += f\"{i}. **{result['title']}**\\n\"\n",
        "            formatted_results += f\"   {result['body']}\\n\"\n",
        "            formatted_results += f\"   Source: {result['href']}\\n\\n\"\n",
        "\n",
        "        return formatted_results\n",
        "    except Exception as e:\n",
        "        return f\"Error performing web search: {str(e)}\""
      ],
      "metadata": {
        "id": "euTJoBeqz0HV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Interacting with Persona Agents\n",
        "\n",
        "The `persona_agents` dictionary now holds all seven instantiated dissertation committee persona agents. Each agent is configured with its unique system prompt based on the descriptions from `dissertation_committee_personas.ipynb`.\n",
        "\n",
        "The following personas are available:\n",
        "- The Visionary\n",
        "- The Pragmatist\n",
        "- The Detail Devil\n",
        "- The Cheerleader\n",
        "- The Networker\n",
        "- The Scholar\n",
        "- The Mentor\n",
        "\n",
        "The `chat_with_persona_agents()` function below provides an interactive command-line interface to select and chat with any of these persona agents. You can switch between personas or quit the chat system as needed."
      ],
      "metadata": {
        "id": "persona_interaction_intro_markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def weather_info(city: str) -> str:\n",
        "    \"\"\"\n",
        "    Get current weather information for a city using OpenWeatherMap API.\n",
        "    Note: This is a mock implementation for demo purposes.\n",
        "\n",
        "    Args:\n",
        "        city: Name of the city\n",
        "\n",
        "    Returns:\n",
        "        Weather information as a string\n",
        "    \"\"\"\n",
        "    mock_weather = {\n",
        "        \"new york\": {\"temp\": 22, \"condition\": \"Partly Cloudy\", \"humidity\": 65},\n",
        "        \"london\": {\"temp\": 15, \"condition\": \"Rainy\", \"humidity\": 80},\n",
        "        \"tokyo\": {\"temp\": 28, \"condition\": \"Sunny\", \"humidity\": 70},\n",
        "        \"paris\": {\"temp\": 18, \"condition\": \"Overcast\", \"humidity\": 75}\n",
        "    }\n",
        "\n",
        "    city_lower = city.lower()\n",
        "    if city_lower in mock_weather:\n",
        "        weather = mock_weather[city_lower]\n",
        "        return f\"Weather in {city}:\\n\" \\\n",
        "               f\"Temperature: {weather['temp']}¬∞C\\n\" \\\n",
        "               f\"Condition: {weather['condition']}\\n\" \\\n",
        "               f\"Humidity: {weather['humidity']}%\"\n",
        "    else:\n",
        "        return f\"Weather data not available for {city}. (This is a demo with limited cities: New York, London, Tokyo, Paris)\""
      ],
      "metadata": {
        "id": "v2Y_KA0pz2Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def text_analyzer(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Analyze text and provide statistics like word count, character count, etc.\n",
        "\n",
        "    Args:\n",
        "        text: Text to analyze\n",
        "\n",
        "    Returns:\n",
        "        Text analysis results\n",
        "    \"\"\"\n",
        "    if not text.strip():\n",
        "        return \"Please provide text to analyze.\"\n",
        "\n",
        "    words = text.split()\n",
        "    sentences = text.split('.') + text.split('!') + text.split('?')\n",
        "    sentences = [s.strip() for s in sentences if s.strip()]\n",
        "\n",
        "    analysis = f\"Text Analysis Results:\\n\"\n",
        "    analysis += f\"‚Ä¢ Characters (with spaces): {len(text)}\\n\"\n",
        "    analysis += f\"‚Ä¢ Characters (without spaces): {len(text.replace(' ', ''))}\\n\"\n",
        "    analysis += f\"‚Ä¢ Words: {len(words)}\\n\"\n",
        "    analysis += f\"‚Ä¢ Sentences: {len(sentences)}\\n\"\n",
        "    analysis += f\"‚Ä¢ Average words per sentence: {len(words) / max(len(sentences), 1):.1f}\\n\"\n",
        "    analysis += f\"‚Ä¢ Most common word: {max(set(words), key=words.count) if words else 'N/A'}\"\n",
        "\n",
        "    return analysis"
      ],
      "metadata": {
        "id": "IV4vqT2Lz5w1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def current_time() -> str:\n",
        "    \"\"\"\n",
        "    Get the current date and time.\n",
        "\n",
        "    Returns:\n",
        "        Current date and time as a formatted string\n",
        "    \"\"\"\n",
        "    now = datetime.now()\n",
        "    return f\"Current date and time: {now.strftime('%Y-%m-%d %H:%M:%S')}\""
      ],
      "metadata": {
        "id": "O9hqLJoDz7Yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_persona_llm(persona_system_prompt: str, anthropic_api_key: str):\n",
        "    if anthropic_api_key and anthropic_api_key != \"Use Your API Key Here\" and anthropic_api_key != \"\":\n",
        "        return ChatAnthropic(\n",
        "            model=\"claude-3-haiku-20240307\",\n",
        "            temperature=0.1,\n",
        "            max_tokens=1024,\n",
        "            system=persona_system_prompt\n",
        "        )\n",
        "    else:\n",
        "        class MockPersonaLLM:\n",
        "            def __init__(self, system_prompt: str):\n",
        "                self.system_prompt = system_prompt\n",
        "                print(f\"‚ö†Ô∏è MockLLM initialized with persona prompt: {self.system_prompt[:100].replace('\\n', ' ')}...\")\n",
        "\n",
        "            def invoke(self, messages):\n",
        "                last_message = messages[-1].content if messages else \"\"\n",
        "                # Simple mock logic - you can expand this to be more persona-aware\n",
        "                if any(word in last_message.lower() for word in ['calculate', 'math', '+', '-', '*', '/', 'sqrt', 'sin', 'cos']):\n",
        "                    import re\n",
        "                    numbers = re.findall(r'[\\d\\+\\-\\*/\\.\\(\\)\\s\\w]+', last_message)\n",
        "                    expr = numbers[0] if numbers else \"2+2\"\n",
        "                    return AIMessage(content=f\"[Mock based on: {self.system_prompt[:30].replace('\\n', ' ')}...] I'll help with calculation.\",\n",
        "                                   tool_calls=[{\"name\": \"calculator\", \"args\": {\"expression\": expr.strip()}, \"id\": \"calc1\"}])\n",
        "                elif any(word in last_message.lower() for word in ['search', 'find', 'look up', 'information about']):\n",
        "                    query = last_message.replace('search for', '').replace('find', '').replace('look up', '').strip()\n",
        "                    if not query or len(query) < 3:\n",
        "                        query = \"python programming\"\n",
        "                    return AIMessage(content=f\"[Mock based on: {self.system_prompt[:30].replace('\\n', ' ')}...] I'll search for that.\",\n",
        "                                   tool_calls=[{\"name\": \"web_search\", \"args\": {\"query\": query}, \"id\": \"search1\"}])\n",
        "                else:\n",
        "                    return AIMessage(content=f\"[Mock based on: {self.system_prompt[:30].replace('\\n', ' ')}...] Hello! How can I assist based on my persona characteristics? I can use calculator, web_search, weather_info, text_analyzer, current_time.\")\n",
        "\n",
        "            def bind_tools(self, tools_list):\n",
        "                # In a real scenario, this might influence how the mock responds or what tools it claims to use.\n",
        "                print(f\"MockLLM tools bound: {[tool.name for tool in tools_list]}\")\n",
        "                return self\n",
        "        \n",
        "        print(\"‚ö†Ô∏è  Note: Using mock LLM for demo. Add your ANTHROPIC_API_KEY for full functionality.\")\n",
        "        return MockPersonaLLM(persona_system_prompt)\n",
        "\n",
        "def create_persona_agent(persona_name: str, persona_system_prompt: str, tools_list: list, anthropic_api_key: str) -> Any:\n",
        "    # 1. Create persona-specific LLM\n",
        "    persona_llm = create_persona_llm(persona_system_prompt, anthropic_api_key)\n",
        "    \n",
        "    # 2. Bind tools to this LLM\n",
        "    persona_llm_with_tools = persona_llm.bind_tools(tools_list)\n",
        "\n",
        "    # 3. Define agent node and should_continue for this specific agent\n",
        "    def persona_agent_node(state: AgentState) -> Dict[str, Any]:\n",
        "        messages = state[\"messages\"]\n",
        "        response = persona_llm_with_tools.invoke(messages) # Uses persona-specific LLM\n",
        "        return {\"messages\": [response]}\n",
        "\n",
        "    def persona_should_continue(state: AgentState) -> str:\n",
        "        last_message = state[\"messages\"][-1]\n",
        "        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
        "            return \"tools\"\n",
        "        return END\n",
        "\n",
        "    # 4. Define the graph structure\n",
        "    tool_node = ToolNode(tools_list) # Use the provided tools_list\n",
        "    workflow = StateGraph(AgentState)\n",
        "    workflow.add_node(\"agent\", persona_agent_node)\n",
        "    workflow.add_node(\"tools\", tool_node)\n",
        "    workflow.add_edge(START, \"agent\")\n",
        "    workflow.add_conditional_edges(\"agent\", persona_should_continue, {\"tools\": \"tools\", END: END})\n",
        "    workflow.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "    # 5. Compile the graph with a MemorySaver\n",
        "    memory = MemorySaver() \n",
        "    app = workflow.compile(checkpointer=memory)\n",
        "    \n",
        "    print(f\"‚úì Persona agent '{persona_name}' created successfully!\")\n",
        "    return app"
      ],
      "metadata": {
        "id": "new_persona_functions_cell" 
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [calculator, web_search, weather_info, text_analyzer, current_time]\n",
        "\n",
        "def create_llm():\n",
        "    # This is the original LLM creator, without a specific persona system prompt by default\n",
        "    # For a generic agent, one might pass a generic system prompt or none like before.\n",
        "    if ANTHROPIC_API_KEY and ANTHROPIC_API_KEY != \"Use Your API Key Here\" and ANTHROPIC_API_KEY != \"\":\n",
        "        return ChatAnthropic(\n",
        "            model=\"claude-3-haiku-20240307\",\n",
        "            temperature=0.1,\n",
        "            max_tokens=1024\n",
        "            # No explicit 'system' prompt here for the generic one, or a default one.\n",
        "        )\n",
        "    else:\n",
        "        class MockLLM:\n",
        "            def __init__(self):\n",
        "                print(f\"‚ö†Ô∏è Original MockLLM initialized without specific persona prompt.\")\n",
        "\n",
        "            def invoke(self, messages):\n",
        "                last_message = messages[-1].content if messages else \"\"\n",
        "\n",
        "                if any(word in last_message.lower() for word in ['calculate', 'math', '+', '-', '*', '/', 'sqrt', 'sin', 'cos']):\n",
        "                    import re\n",
        "                    numbers = re.findall(r'[\\d\\+\\-\\*/\\.\\(\\)\\s\\w]+', last_message)\n",
        "                    expr = numbers[0] if numbers else \"2+2\"\n",
        "                    return AIMessage(content=\"I'll help you with that calculation.\",\n",
        "                                   tool_calls=[{\"name\": \"calculator\", \"args\": {\"expression\": expr.strip()}, \"id\": \"calc1\"}])\n",
        "                elif any(word in last_message.lower() for word in ['search', 'find', 'look up', 'information about']):\n",
        "                    query = last_message.replace('search for', '').replace('find', '').replace('look up', '').strip()\n",
        "                    if not query or len(query) < 3:\n",
        "                        query = \"python programming\"\n",
        "                    return AIMessage(content=\"I'll search for that information.\",\n",
        "                                   tool_calls=[{\"name\": \"web_search\", \"args\": {\"query\": query}, \"id\": \"search1\"}])\n",
        "                elif any(word in last_message.lower() for word in ['weather', 'temperature']):\n",
        "                    city = \"New York\"\n",
        "                    words = last_message.lower().split()\n",
        "                    for i, word in enumerate(words):\n",
        "                        if word == 'in' and i + 1 < len(words):\n",
        "                            city = words[i + 1].title()\n",
        "                            break\n",
        "                    return AIMessage(content=\"I'll get the weather information.\",\n",
        "                                   tool_calls=[{\"name\": \"weather_info\", \"args\": {\"city\": city}, \"id\": \"weather1\"}])\n",
        "                elif any(word in last_message.lower() for word in ['time', 'date']):\n",
        "                    return AIMessage(content=\"I'll get the current time.\",\n",
        "                                   tool_calls=[{\"name\": \"current_time\", \"args\": {}, \"id\": \"time1\"}])\n",
        "                elif any(word in last_message.lower() for word in ['analyze', 'analysis']):\n",
        "                    text = last_message.replace('analyze this text:', '').replace('analyze', '').strip()\n",
        "                    if not text:\n",
        "                        text = \"Sample text for analysis\"\n",
        "                    return AIMessage(content=\"I'll analyze that text for you.\",\n",
        "                                   tool_calls=[{\"name\": \"text_analyzer\", \"args\": {\"text\": text}, \"id\": \"analyze1\"}])\n",
        "                else:\n",
        "                    return AIMessage(content=\"Hello! I'm a multi-tool agent powered by Claude. I can help with:\\n‚Ä¢ Mathematical calculations\\n‚Ä¢ Web searches\\n‚Ä¢ Weather information\\n‚Ä¢ Text analysis\\n‚Ä¢ Current time/date\\n\\nWhat would you like me to help you with?\")\n",
        "\n",
        "            def bind_tools(self, tools_list):\n",
        "                print(f\"Original MockLLM tools bound: {[tool.name for tool in tools_list]}\")\n",
        "                return self\n",
        "\n",
        "        print(\"‚ö†Ô∏è  Note: Using original mock LLM for demo. Add your ANTHROPIC_API_KEY for full functionality.\")\n",
        "        return MockLLM()\n",
        "\n",
        "llm = create_llm() # This will now call the slightly modified original create_llm\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "zfE4b5d60CMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "personas_data = [\n",
        "  {\n",
        "    \"name\": \"1. The Visionary (Professor of Emerging Educational Technologies)\",\n",
        "    \"description\": \"The Visionary, often a Professor specializing in Educational Technology with a focus on emerging tech like AI, VR, or adaptive learning systems, is a big-picture thinker. They see your dissertation's potential to revolutionize learning and will encourage you to explore cutting-edge EdTech innovations. They're great for brainstorming transformative research questions but might be less focused on immediate practical constraints of current school systems.\",\n",
        "    \"strengths\": \"Encourages groundbreaking use of EdTech, future-oriented, helps broaden your perspective on what's possible in education with technology.\",\n",
        "    \"weaknesses\": \"May overlook current technological limitations, budget constraints, or practical implementation challenges in diverse educational settings; might push for projects that are difficult to scope.\",\n",
        "    \"best_for\": \"Students wanting to explore futuristic EdTech applications, conduct design-based research with novel technologies, or challenge existing paradigms in education.\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"2. The Pragmatist (Professor of Organizational Performance & Workplace Learning or EdTech Implementation)\",\n",
        "    \"description\": \"The Pragmatist, often with a background in Organizational Performance & Workplace Learning (OPWL) or EdTech implementation science, is all about feasibility and impact. They'll help you define a realistic project scope, develop a clear methodology for evaluating EdTech effectiveness, and navigate institutional hurdles for deployment. They're excellent for ensuring your EdTech solution is practical, user-centered, and leads to measurable outcomes.\",\n",
        "    \"strengths\": \"Focuses on timely completion and real-world application, provides practical guidance on project management and EdTech evaluation, ensures solutions are effective and efficient.\",\n",
        "    \"weaknesses\": \"May discourage overly ambitious or purely theoretical EdTech research without clear, immediate application; might prioritize efficiency over radical innovation.\",\n",
        "    \"best_for\": \"Students focusing on EdTech implementation, instructional design for corporate or adult learning, usability studies, or program evaluation within educational or organizational contexts.\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"3. The Detail Devil (Professor of Research Methods in Education)\",\n",
        "    \"description\": \"The Detail Devil, typically a professor specializing in Research Methods, has an eagle eye for methodological flaws, statistical errors, and inconsistencies in your argument, especially as they apply to EdTech research. They'll meticulously review your research design, data analysis plans, and interpretations, ensuring your work is rigorous and defensible. They're invaluable for producing high-quality, publishable EdTech research.\",\n",
        "    \"strengths\": \"Ensures methodological soundness and analytical rigor in EdTech studies, helps produce a flawless and credible final product, strong in quantitative and/or qualitative analysis.\",\n",
        "    \"weaknesses\": \"May get bogged down in minute methodological details, potentially slowing progress if not balanced with broader research goals; could be perceived as overly critical if feedback is not constructive.\",\n",
        "    \"best_for\": \"Students needing strong guidance on complex research designs (e.g., experimental, quasi-experimental, mixed-methods), advanced statistical analysis, or robust qualitative methods for their EdTech research.\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"4. The Cheerleader (Professor of Teaching & Learning with Technology)\",\n",
        "    \"description\": \"The Cheerleader, often a professor passionate about Teaching & Learning with Technology or K-12 EdTech integration, is your biggest advocate. They believe in the transformative power of your EdTech project for students and educators and will be a constant source of encouragement. They're great for pedagogical brainstorming, user empathy, and maintaining motivation, especially when working on projects aimed at improving classroom practices.\",\n",
        "    \"strengths\": \"Provides motivation and pedagogical support for EdTech integration, champions student ideas, helps you stay positive and focused on the educational impact.\",\n",
        "    \"weaknesses\": \"May not always provide the most critical feedback on the technological design or research methodology if the pedagogical vision is compelling; might be less focused on the technical nitty-gritty.\",\n",
        "    \"best_for\": \"Students needing encouragement and pedagogical inspiration, especially those developing EdTech interventions for K-12, exploring innovative teaching models with technology, or focusing on teacher professional development.\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"5. The Networker (Professor with ties to EdTech Industry/Policy or Higher Education Leadership)\",\n",
        "    \"description\": \"The Networker, perhaps a professor with strong connections to the EdTech industry, policymakers, or Higher Education Leadership circles, has a vast web of contacts. They can open doors to collaborations with EdTech companies, research partnerships, funding opportunities, or even post-graduation employment. They're great for expanding your professional circle and increasing the visibility and potential impact of your EdTech work.\",\n",
        "    \"strengths\": \"Facilitates networking with EdTech professionals, policymakers, or school leaders; creates opportunities for external funding, pilot sites, or career advancement.\",\n",
        "    \"weaknesses\": \"Direct, detailed research or methodological guidance might be secondary to making connections; focus might be more on dissemination and impact than on initial research design.\",\n",
        "    \"best_for\": \"Students whose EdTech projects have strong potential for real-world impact, those interested in EdTech entrepreneurship, policy research, or leadership roles requiring strong external connections.\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"6. The Scholar (Professor specializing in a specific domain like Literacy & Technology or STEM Education)\",\n",
        "    \"description\": \"The Scholar is a leading expert in a specific niche within EdTech, such as Literacy and Technology, Math Education, or STEM Education. They have a deep understanding of the existing literature and theoretical frameworks in their domain. They'll challenge you to engage with the theoretical underpinnings of your research and ensure your work is situated within this specific scholarly conversation, contributing meaningfully to it.\",\n",
        "    \"strengths\": \"Encourages deep theoretical engagement within a specific EdTech domain (e.g., literacy, STEM), ensures scholarly rigor and contribution to that field, strong on literature review and theoretical framing.\",\n",
        "    \"weaknesses\": \"May push for highly specialized theoretical debates within their niche, potentially overlooking broader EdTech applications or interdisciplinary connections; might be less familiar with EdTech areas outside their specialization.\",\n",
        "    \"best_for\": \"Students conducting EdTech research within a specific subject area (e.g., technology for bilingual education, math education games) or who want to engage deeply with specific learning theories as they apply to technology.\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"7. The Mentor (Senior Professor in Educational Leadership or EdTech)\",\n",
        "    \"description\": \"The Mentor, often a seasoned professor with experience in Educational Leadership or a long career in Educational Technology, takes a holistic approach to your development. They'll not only guide your research but also offer career advice, support for navigating academic politics in the EdTech field, and help you understand the 'hidden curriculum' of becoming a scholar or EdTech professional. They're invested in your long-term success and well-being within the EdTech community.\",\n",
        "    \"strengths\": \"Provides comprehensive guidance on research and career, fosters personal and professional growth within the EdTech field, helps navigate complex academic or professional landscapes.\",\n",
        "    \"weaknesses\": \"May not be an expert in the very latest EdTech tool or specific niche research area, but possesses broad wisdom; might have significant service or administrative commitments limiting availability.\",\n",
        "    \"best_for\": \"Students looking for a long-term mentor who can guide them through the dissertation process and into their career in Educational Technology or related fields, offering wisdom beyond the immediate research project.\"\n",
        "  }\n",
        "]"
      ],
      "metadata": {
        "id": "persona_data_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "persona_system_prompts = {}\n",
        "persona_agents = {}\n",
        "\n",
        "for persona in personas_data:\n",
        "    # Construct the detailed system prompt\n",
        "    system_prompt = (\n",
        "        f\"You are {persona['name']}. \"\n",
        "        f\"Your background is: {persona['description']}. \"\n",
        "        f\"Your key strengths include: {persona['strengths']}. \"\n",
        "        f\"However, you sometimes struggle with: {persona['weaknesses']}. \"\n",
        "        f\"You are an AI assistant that embodies this persona. Your primary goal is to assist users with tasks using the available tools, while consistently reflecting your persona's characteristics, EdTech specialization, and communication style. \"\n",
        "        f\"Consider who you are 'Best for': {persona['best_for']} when advising or responding. \"\n",
        "        f\"Always maintain your persona's characteristics in your responses and tool usage.\"\n",
        "    )\n",
        "    \n",
        "    # Extract a short name for the dictionary key, removing the number and parenthesis content\n",
        "    match = re.match(r\"\\d+\\.\\s*The\\s*([^\\(]+)\", persona['name'])\n",
        "    short_name = match.group(1).strip() if match else persona['name']\n",
        "    \n",
        "    persona_system_prompts[short_name] = system_prompt\n",
        "    \n",
        "    print(f\"Creating agent for: {short_name}...\")\n",
        "    # Ensure `tools` variable is available in this scope, and ANTHROPIC_API_KEY is set\n",
        "    created_agent = create_persona_agent(\n",
        "        persona_name=short_name, \n",
        "        persona_system_prompt=system_prompt, \n",
        "        tools_list=tools, # This 'tools' list should be the one defined earlier in the notebook\n",
        "        anthropic_api_key=ANTHROPIC_API_KEY\n",
        "    )\n",
        "    persona_agents[short_name] = created_agent\n",
        "\n",
        "print(\"\\n--- All Persona Agents Created ---\")\n",
        "for name in persona_agents.keys():\n",
        "    print(f\"- {name} Agent\")\n",
        "print(\"\\nAccess individual agents via the `persona_agents` dictionary, e.g., persona_agents['The Visionary']\")"
      ],
      "metadata": {
        "id": "persona_instantiation_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def agent_node(state: AgentState) -> Dict[str, Any]:\n",
        "    \"\"\"Main agent node that processes messages and decides on tool usage (for the original generic agent).\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    response = llm_with_tools.invoke(messages)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "def should_continue(state: AgentState) -> str:\n",
        "    \"\"\"Determine whether to continue with tool calls or end (for the original generic agent).\"\"\"\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    return END"
      ],
      "metadata": {
        "id": "2TPO8nI40EP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Original Generic Agent Creation (Optional)\n",
        "\n",
        "The cell below defines the creation of the original, generic agent. With the introduction of persona agents, this is now optional and primarily for comparison or if a non-persona-specific agent is needed."
      ],
      "metadata": {
        "id": "original_agent_creation_markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_agent_graph():\n",
        "    tool_node = ToolNode(tools)\n",
        "\n",
        "    workflow = StateGraph(AgentState)\n",
        "\n",
        "    workflow.add_node(\"agent\", agent_node)\n",
        "    workflow.add_node(\"tools\", tool_node)\n",
        "\n",
        "    workflow.add_edge(START, \"agent\")\n",
        "    workflow.add_conditional_edges(\"agent\", should_continue, {\"tools\": \"tools\", END: END})\n",
        "    workflow.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "    memory = MemorySaver()\n",
        "\n",
        "    app = workflow.compile(checkpointer=memory)\n",
        "\n",
        "    return app\n",
        "\n",
        "print(\"Creating original LangGraph Multi-Tool Agent (generic)...\")\n",
        "agent = create_agent_graph() # This is the original generic agent\n",
        "print(\"‚úì Original generic agent created successfully!\\n\")"
      ],
      "metadata": {
        "id": "GbVXP-JR0KSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def test_agent():\n",
        "#     \"\"\"Test the agent with various queries.\"\"\"\n",
        "#     config = {\"configurable\": {\"thread_id\": \"test-thread\"}}\n",
        "# \n",
        "#     test_queries = [\n",
        "#         \"What's 15 * 7 + 23?\",\n",
        "#         \"Search for information about Python programming\",\n",
        "#         \"What's the weather like in Tokyo?\",\n",
        "#         \"What time is it?\",\n",
        "#         \"Analyze this text: 'LangGraph is an amazing framework for building AI agents.'\"\n",
        "#     ]\n",
        "# \n",
        "#     print(\"üß™ Testing the agent with sample queries...\\n\")\n",
        "# \n",
        "#     for i, query in enumerate(test_queries, 1):\n",
        "#         print(f\"Query {i}: {query}\")\n",
        "#         print(\"-\" * 50)\n",
        "# \n",
        "#         try:\n",
        "#             response = agent.invoke(\n",
        "#                 {\"messages\": [HumanMessage(content=query)]},\n",
        "#                 config=config\n",
        "#             )\n",
        "# \n",
        "#             last_message = response[\"messages\"][-1]\n",
        "#             print(f\"Response: {last_message.content}\\n\")\n",
        "# \n",
        "#         except Exception as e:\n",
        "#             print(f\"Error: {str(e)}\\n\")"
      ],
      "metadata": {
        "id": "h4ZknozS0OoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def chat_with_agent():\n",
        "#     \"\"\"Interactive chat function.\"\"\"\n",
        "#     config = {\"configurable\": {\"thread_id\": \"interactive-thread\"}}\n",
        "# \n",
        "#     print(\"ü§ñ Multi-Tool Agent Chat\")\n",
        "#     print(\"Available tools: Calculator, Web Search, Weather Info, Text Analyzer, Current Time\")\n",
        "#     print(\"Type 'quit' to exit, 'help' for available commands\\n\")\n",
        "# \n",
        "#     while True:\n",
        "#         try:\n",
        "#             user_input = input(\"You: \").strip()\n",
        "# \n",
        "#             if user_input.lower() in ['quit', 'exit', 'q']:\n",
        "#                 print(\"Goodbye!\")\n",
        "#                 break\n",
        "#             elif user_input.lower() == 'help':\n",
        "#                 print(\"\\nAvailable commands:\")\n",
        "#                 print(\"‚Ä¢ Calculator: 'Calculate 15 * 7 + 23' or 'What's sin(pi/2)?'\")\n",
        "#                 print(\"‚Ä¢ Web Search: 'Search for Python tutorials' or 'Find information about AI'\")\n",
        "#                 print(\"‚Ä¢ Weather: 'Weather in Tokyo' or 'What's the temperature in London?'\")\n",
        "#                 print(\"‚Ä¢ Text Analysis: 'Analyze this text: [your text]'\")\n",
        "#                 print(\"‚Ä¢ Current Time: 'What time is it?' or 'Current date'\")\n",
        "#                 print(\"‚Ä¢ quit: Exit the chat\\n\")\n",
        "#                 continue\n",
        "#             elif not user_input:\n",
        "#                 continue\n",
        "# \n",
        "#             response = agent.invoke(\n",
        "#                 {\"messages\": [HumanMessage(content=user_input)]},\n",
        "#                 config=config\n",
        "#             )\n",
        "# \n",
        "#             last_message = response[\"messages\"][-1]\n",
        "#             print(f\"Agent: {last_message.content}\\n\")\n",
        "# \n",
        "#         except KeyboardInterrupt:\n",
        "#             print(\"\\nGoodbye!\")\n",
        "#             break\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error: {str(e)}\\n\")"
      ],
      "metadata": {
        "id": "mVlzGSST0UQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ76rlnFwIuE",
        "outputId": "4912a6ee-a52a-4a94-897b-093bce64626e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required packages...\n",
            "‚úì Installed langgraph\n",
            "‚úì Installed langchain\n",
            "‚úì Installed langchain-anthropic\n",
            "‚úì Installed langchain-community\n",
            "‚úì Installed requests\n",
            "‚úì Installed python-dotenv\n",
            "‚úì Installed duckduckgo-search\n",
            "Installation complete!\n",
            "\n",
            "Creating LangGraph Multi-Tool Agent...\n",
            "‚úì Agent created successfully!\n",
            "\n",
            "üß™ Testing the agent with sample queries...\n",
            "\n",
            "Query 1: What's 15 * 7 + 23?\n",
            "--------------------------------------------------\n",
            "Response: So, 15 * 7 + 23 = 128.\n",
            "\n",
            "Query 2: Search for information about Python programming\n",
            "--------------------------------------------------\n",
            "Response: These search results provide a good overview of Python programming, including the official Python website, Wikipedia article, and a popular tutorial from W3Schools. Let me know if you need any other information!\n",
            "\n",
            "Query 3: What's the weather like in Tokyo?\n",
            "--------------------------------------------------\n",
            "Response: Based on the weather information, it looks like the weather in Tokyo is sunny with a temperature of 28¬∞C (around 82¬∞F) and 70% humidity.\n",
            "\n",
            "Query 4: What time is it?\n",
            "--------------------------------------------------\n",
            "Response: The current date and time is 2025-05-22 20:57:38.\n",
            "\n",
            "Query 5: Analyze this text: 'LangGraph is an amazing framework for building AI agents.'\n",
            "--------------------------------------------------\n",
            "Response: The key insights from the text analysis are:\n",
            "- The text has 57 characters (including spaces) and 49 characters without spaces.\n",
            "- It contains 9 words across 3 sentences, with an average of 3 words per sentence.\n",
            "- The most common word in the text is \"building\".\n",
            "\n",
            "Overall, this is a short, concise sentence describing LangGraph as an amazing framework for building AI agents.\n",
            "\n",
            "============================================================\n",
            "üéâ LangGraph Multi-Tool Agent is ready!\n",
            "============================================================\n",
            "ü§ñ Multi-Tool Agent Chat\n",
            "Available tools: Calculator, Web Search, Weather Info, Text Analyzer, Current Time\n",
            "Type 'quit' to exit, 'help' for available commands\n",
            "\n",
            "You: exit\n",
            "Goodbye!\n",
            "\n",
            "============================================================\n",
            "üîß Usage Instructions:\n",
            "1. Add your ANTHROPIC_API_KEY to use Claude model\n",
            "   os.environ['ANTHROPIC_API_KEY'] = 'your-anthropic-api-key'\n",
            "2. Run quick_demo() for a quick demonstration\n",
            "3. Run chat_with_agent() for interactive chat\n",
            "4. The agent supports: calculations, web search, weather, text analysis, and time\n",
            "5. Example: 'Calculate 15*7+23' or 'Search for Python tutorials'\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # The old test_agent() and chat_with_agent() calls are commented out as they use the generic 'agent'.\n",
        "    # The quick_demo() definition is also commented out.\n",
        "\n",
        "    # Call the new persona chat system if persona_agents is populated\n",
        "    if 'persona_agents' in globals() and persona_agents:\n",
        "        print(\"\\nüöÄ Starting Persona Agent Chat System...\")\n",
        "        chat_with_persona_agents() # This is the primary interaction method now.\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è Persona agents dictionary ('persona_agents') not found or not initialized.\")\n",
        "        print(\"   Please ensure previous cells, especially persona creation, have run successfully.\")\n",
        "        print(\"   The original generic agent might still be available for testing if its creation cell was run (cell ID: GbVXP-JR0KSt).\")\n",
        "\n",
        "# def quick_demo():\n",
        "#     \"\"\"Quick demonstration of agent capabilities.\"\"\"\n",
        "#     # This function would need to be updated to use one of the persona_agents if reactivated.\n",
        "#     # For example, to demo 'The Visionary':\n",
        "#     # visionary_agent = persona_agents.get(\"The Visionary\")\n",
        "#     # if visionary_agent:\n",
        "#     #     config = {\"configurable\": {\"thread_id\": \"demo-visionary\"}}\n",
        "#     #     # ... rest of demo logic using visionary_agent ...\n",
        "#     # else:\n",
        "#     #     print(\"Visionary agent not found for demo.\")\n",
        "#     pass \n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üîß Usage Instructions (Updated for Persona Agents):\")\n",
        "print(\"1. Set your ANTHROPIC_API_KEY in cell with ID 'bcmEtjBCzn42' to use the Claude model.\")\n",
        "print(\"2. Run all preceding cells to install packages, define tools, and create the seven persona agents.\")\n",
        "print(\"3. The notebook will automatically start the `chat_with_persona_agents()` function if run completely.\")\n",
        "print(\"4. In the chat interface, you can select a persona by number or name to interact with it.\")\n",
        "print(\"5. Each persona agent has access to the same set of tools (Calculator, Web Search, etc.) but will respond according to its defined persona.\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "froVp5isziN3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}